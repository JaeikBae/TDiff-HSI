![Graphical Abstract](img/Graphical%20Abstract_new.png)

ğŸŒ [En](#en) | ğŸ‡°ğŸ‡· [Ko](#ko)

<a id="en"></a>
## Model and Dataset Release ğŸš€

ğŸ§­ Contents

- [Assets Summary](#en-assets)
- [Download](#en-download)
- [Docker](#en-docker)
- [Quickstart: Inference](#en-inference)
- [Reproducing Training](#en-train)
- [Paper](#en-paper)
- [Contact](#en-contact)

This repository releases both the trained model and the datasets used for training/evaluation. Datasets are provided in two archive formats: `tar` and `zip`. Trained model weights are provided as `.pth` files (two parts: diffusion and upsample).

You can selectively download only what you need. Large files are distributed via Google Drive links.

<a id="en-assets"></a>
### ğŸ“¦ Assets Summary

Pick one of the two dataset archives (tar/zip). Content is identical.

| Item | Description | Format | Link |
|---|---|---|---|
| Dataset (tar) | Train/Val/Test data | `.tar` | [Dataset (tar)](https://drive.google.com/file/d/1LuJwGNK6Mrk7TyBFuQk-311IQa_TweOR/view?usp=sharing) |
| Dataset (zip) | Train/Val/Test data | `.zip` | [Dataset (zip)](https://drive.google.com/file/d/1z8WR81dqdwKS4E5PIkzxoB1a1HVTHijS/view?usp=sharing) |
| Diffusion model weights | Trained diffusion model | `.pth` | [Download](https://drive.google.com/file/d/10dV23EDZmOAytgbXDNPwZ6essYvBriF3/view?usp=sharing) |
| Upsample model weights | Trained upsample model | `.pth` | [Download](https://drive.google.com/file/d/1dEKVPADcDYf1Q5sCw4vqarhSla18pzxB/view?usp=sharing) |

<a id="en-download"></a>
### â¬‡ï¸ Download

- Manual: Open the Google Drive links above in your browser.

<a id="en-extract"></a>
### ğŸ“‚ Extract Archives

```bash
# tar archives (dataset only)
tar -xvf dataset.tar -C /desired/path

# zip archives (dataset only)
unzip dataset.zip -d /desired/path
```

<a id="en-structure"></a>
### ğŸ—‚ï¸ Dataset Directory Structure (Example)

```text
dataset_root/
  train/
    ...
  val/
    ...
  test/
    ...
```

The exact sub-structure and file formats may vary by project. Please update this README to reflect the actual released dataset structure.

<a id="en-env"></a>
### ğŸ› ï¸ Environment Setup

```bash
python -V                 # Check Python version (recommended: 3.9+)
pip install -r requirements.txt
```

Tips

- Use GPU if available for both training and inference.
- Default paths assume running inside the container with `/app` as project root.

<a id="en-docker"></a>
### ğŸ³ Docker

Build and run with Docker (requires Docker installed):

```bash
# Build image
docker build -t diffusion-hsi-img -f Dockerfile .

# Run container (GPU + larger shared memory recommended)
docker run --rm -it \
  --gpus all \
  --shm-size=64G \
  -v $(pwd):/app \
  diffusion-hsi-img bash

# (Optional) using the provided helper
bash docker_build_run.sh
```

<a id="en-inference"></a>
### âš¡ Quickstart: Inference

Run the evaluation/inference script:

```bash
python models/test.py \
  --data_dir /app/datas/hsi \
  --model /app/weights/diffusion_model.pth \
  --upsample_model /app/weights/upsample_model.pth \
  --save_base /app/results
```

<a id="en-train"></a>
### ğŸ” Reproducing Training

Option A (recommended helper):

```bash
cd models
bash run_train_diffusion.sh 4 \
  --data_dir /app/datas/hsi \
  --data_dir_test /app/datas/val \
  --save_dir /app/weights \
  --batch_size 2 \
  --epochs 5000 \
  --num_workers 4
```

Option B (direct):

```bash
OMP_NUM_THREADS=16 \
torchrun --standalone --nnodes=1 --nproc_per_node=4 \
  models/train_diffusion.py \
  --data_dir /app/datas/hsi \
  --data_dir_test /app/datas/val \
  --save_dir /app/weights \
  --batch_size 2 \
  --epochs 5000 \
  --num_workers 4
```

Checkpoints will be saved under `/app/weights` at the configured intervals.

<a id="en-paper"></a>
### ğŸ“„ Paper

Paper: <TBA>

<a id="en-contact"></a>
### âœ‰ï¸ Contact

Please open a GitHub Issue or reach out via:

- Email: jaeikb38@gm.gist.ac.kr

---

â„¹ï¸ Note: The following section is in Korean.
<a id="ko"></a>

## ëª¨ë¸ ë° ë°ì´í„° ê³µê°œ ì•ˆë‚´ ğŸš€

ğŸŒ [En](#en) | [Ko](#ko)

ğŸ§­ ëª©ì°¨

- [êµ¬ì„± ìš”ì•½](#ko-assets)
- [ë‹¤ìš´ë¡œë“œ ë°©ë²•](#ko-download)
- [ì••ì¶• í•´ì œ](#ko-extract)
- [ë°ì´í„°ì…‹ ë””ë ‰í„°ë¦¬ êµ¬ì¡°](#ko-structure)
- [í™˜ê²½ ì¤€ë¹„](#ko-env)
- [Docker](#ko-docker)
- [ë¹ ë¥¸ ì‹œì‘: ì¶”ë¡ (Inference)](#ko-inference)
- [í•™ìŠµ(Training) ì¬í˜„](#ko-train)
- [ë…¼ë¬¸](#ko-paper)
- [ë¬¸ì˜](#ko-contact)

ì´ ì €ì¥ì†ŒëŠ” í•™ìŠµëœ ëª¨ë¸ê³¼ í•™ìŠµ/í‰ê°€ì— ì‚¬ìš©ëœ ë°ì´í„°ì…‹ì„ í•¨ê»˜ ê³µê°œí•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ `tar`ì™€ `zip` ë‘ ê°€ì§€ ì••ì¶• í˜•ì‹ìœ¼ë¡œ ì œê³µë˜ë©°, í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” `.pth` íŒŒì¼(ë””í“¨ì „/ì—…ìƒ˜í”Œ 2íŒŒíŠ¸)ë¡œ ì œê³µí•©ë‹ˆë‹¤.

í•„ìš”í•œ í•­ëª©ë§Œ ê³¨ë¼ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìœ¼ë©°, ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ Google Drive ë§í¬ë¥¼ í†µí•´ ë‹¤ìš´ë¡œë“œí•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<a id="ko-assets"></a>
### ğŸ“¦ êµ¬ì„± ìš”ì•½

| í•­ëª© | ì„¤ëª… | í˜•ì‹ | ë§í¬ |
|---|---|---|---|
| ë°ì´í„°ì…‹ (tar) | í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° | `.tar` | [ë°ì´í„°ì…‹ (tar)](https://drive.google.com/file/d/1LuJwGNK6Mrk7TyBFuQk-311IQa_TweOR/view?usp=sharing) |
| ë°ì´í„°ì…‹ (zip) | í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° | `.zip` | [ë°ì´í„°ì…‹ (zip)](https://drive.google.com/file/d/1z8WR81dqdwKS4E5PIkzxoB1a1HVTHijS/view?usp=sharing) |
| ë””í“¨ì „ ëª¨ë¸ ê°€ì¤‘ì¹˜ | í•™ìŠµëœ ë””í“¨ì „ ëª¨ë¸ | `.pth` | [ë‹¤ìš´ë¡œë“œ](https://drive.google.com/file/d/1S7MCVovFixrIuOLl7oVWRdlMd5kJwG6r/view?usp=sharing) |
| ì—…ìƒ˜í”Œ ëª¨ë¸ ê°€ì¤‘ì¹˜ | í•™ìŠµëœ ì—…ìƒ˜í”Œ ëª¨ë¸ | `.pth` | [ë‹¤ìš´ë¡œë“œ](https://drive.google.com/file/d/1EyPDn008j1MA-w36OgIwt93xBR8Lo6YB/view?usp=sharing) |

<a id="ko-download"></a>
### â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ë°©ë²•

- ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ: ìœ„ í‘œì˜ Google Drive ë§í¬ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ì–´ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
- CLI ë‹¤ìš´ë¡œë“œ: `gdown`ì„ ì‚¬ìš©í•˜ë©´ ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ì»¤ë§¨ë“œë¼ì¸ì—ì„œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# gdown ì„¤ì¹˜
pip install gdown

# ë°ì´í„°ì…‹ (tar)
gdown --fuzzy "https://drive.google.com/file/d/1LuJwGNK6Mrk7TyBFuQk-311IQa_TweOR/view?usp=sharing"

# ë°ì´í„°ì…‹ (zip)
gdown --fuzzy "https://drive.google.com/file/d/1z8WR81dqdwKS4E5PIkzxoB1a1HVTHijS/view?usp=sharing"

# ë””í“¨ì „ ëª¨ë¸ ê°€ì¤‘ì¹˜
gdown --fuzzy "https://drive.google.com/file/d/1S7MCVovFixrIuOLl7oVWRdlMd5kJwG6r/view?usp=sharing"

# ì—…ìƒ˜í”Œ ëª¨ë¸ ê°€ì¤‘ì¹˜
gdown --fuzzy "https://drive.google.com/file/d/1EyPDn008j1MA-w36OgIwt93xBR8Lo6YB/view?usp=sharing"
```

 

<a id="ko-extract"></a>
### ğŸ“‚ ì••ì¶• í•´ì œ

```bash
# tar í˜•ì‹ (ë°ì´í„°ì…‹ë§Œ í•´ë‹¹)
tar -xvf ë°ì´í„°ì…‹.tar -C ì›í•˜ëŠ”_ê²½ë¡œ

# zip í˜•ì‹ (ë°ì´í„°ì…‹ë§Œ í•´ë‹¹)
unzip ë°ì´í„°ì…‹.zip -d ì›í•˜ëŠ”_ê²½ë¡œ
```

<a id="ko-structure"></a>
### ğŸ—‚ï¸ ë°ì´í„°ì…‹ ë””ë ‰í„°ë¦¬ êµ¬ì¡° (ì˜ˆì‹œ)

```text
dataset_root/
  train/
    ...
  val/
    ...
  test/
    ...
```

í”„ë¡œì íŠ¸ì— ë”°ë¼ í•˜ìœ„ êµ¬ì¡°ì™€ íŒŒì¼ í¬ë§·ì€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ ê³µê°œë˜ëŠ” ë°ì´í„° êµ¬ì¡°ë¥¼ ê°„ë‹¨íˆ READMEì— ë³´ì™„í•´ ì£¼ì„¸ìš”.

<a id="ko-env"></a>
### ğŸ› ï¸ í™˜ê²½ ì¤€ë¹„

```bash
python -V                 # Python ë²„ì „ í™•ì¸ (ê¶Œì¥: 3.9+)
pip install -r requirements.txt
```

<a id="ko-docker"></a>
### ğŸ³ Docker

Dockerë¡œ ë¹Œë“œ ë° ì‹¤í–‰ (Docker ì„¤ì¹˜ í•„ìš”):

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t diffusion-hsi-img -f Dockerfile .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰ (GPU + ì¶©ë¶„í•œ shared memory ê¶Œì¥)
docker run --rm -it \
  --gpus all \
  --shm-size=64G \
  -v $(pwd):/app \
  diffusion-hsi-img bash

# (ì„ íƒ) ì œê³µëœ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
bash docker_build_run.sh
```

<a id="ko-inference"></a>
### âš¡ ë¹ ë¥¸ ì‹œì‘: ì¶”ë¡ (Inference)

í‰ê°€/ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:

```bash
python models/test.py \
  --data_dir /app/datas/hsi \
  --model /app/weights/diffusion_model.pth \
  --upsample_model /app/weights/upsample_model.pth \
  --save_base /app/results
```

<a id="ko-train"></a>
### ğŸ” í•™ìŠµ(Training) ì¬í˜„

ë°©ë²• A (ê¶Œì¥, í—¬í¼ ìŠ¤í¬ë¦½íŠ¸):

```bash
cd models
bash run_train_diffusion.sh 4 \
  --data_dir /app/datas/hsi \
  --data_dir_test /app/datas/val \
  --save_dir /app/weights \
  --batch_size 2 \
  --epochs 5000 \
  --num_workers 4
```

ë°©ë²• B (ì§ì ‘ ì‹¤í–‰):

```bash
OMP_NUM_THREADS=16 \
torchrun --standalone --nnodes=1 --nproc_per_node=4 \
  models/train_diffusion.py \
  --data_dir /app/datas/hsi \
  --data_dir_test /app/datas/val \
  --save_dir /app/weights \
  --batch_size 2 \
  --epochs 5000 \
  --num_workers 4
```

ì²´í¬í¬ì¸íŠ¸ëŠ” ì„¤ì •ëœ ì£¼ê¸°ì— `/app/weights` ì•„ë˜ì— ì €ì¥ë©ë‹ˆë‹¤.

<a id="ko-paper"></a>
### ğŸ“„ ë…¼ë¬¸

ë…¼ë¬¸: <TBA>

 

<a id="ko-contact"></a>
### âœ‰ï¸ ë¬¸ì˜

ì´ìŠˆë‚˜ ì§ˆë¬¸ì€ GitHub Issuesë¥¼ í†µí•´ ë‚¨ê²¨ì£¼ì‹œê±°ë‚˜ ì•„ë˜ ì—°ë½ì²˜ë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.

- ì´ë©”ì¼: jaeikb38@gm.gist.ac.kr



 

